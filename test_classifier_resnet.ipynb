{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use gpu = True\n"
     ]
    }
   ],
   "source": [
    "import glob,pylab,pandas as pd\n",
    "import pydicom,numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import torchvision\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches,patheffects\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from pathlib import Path\n",
    "\n",
    "PATH = Path(\"/data/krf/dataset\")\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self,ds,img_dir,class_df = None,transform=None,ext=None):\n",
    "        self.ds = ds\n",
    "        self.img_dir = img_dir\n",
    "        self.class_df = class_df\n",
    "        self.ext = ext or '.dcm'\n",
    "        self.transform = transforms.Compose(transform) if transform else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def read_dicom_image(self,loc):\n",
    "        img_arr = pydicom.read_file(loc.as_posix()).pixel_array\n",
    "        img_arr = img_arr/img_arr.max()\n",
    "        img_arr = (255*img_arr).clip(0,255).astype(np.uint8)\n",
    "        img_arr = Image.fromarray(img_arr).convert('RGB')\n",
    "        return img_arr\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        img = self.read_dicom_image(self.ds[i])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        patientId = self.ds[i].name.split('.')[0]\n",
    "        #kls = self.class_df[self.class_df['patientId'] == patientId]\n",
    "        return img,patientId#,kls.iloc[0].Target\n",
    "\n",
    "\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(\"Use gpu = {}\".format(use_gpu))\n",
    "\n",
    "#dataloaders = {'train':train_dl,'val':test_dl}\n",
    "\n",
    "device = torch.cuda.set_device(0)\n",
    "\n",
    "\n",
    "model_ft = torchvision.models.resnet18(pretrained=False)#True)\n",
    "#修改分类数\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs,2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters())\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft,step_size=7,gamma=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.load_state_dict(torch.load('resnet.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = PATH/'stage_1_test_images'\n",
    "#img_dir = PATH/'stage_1_test_images'\n",
    "#sample = random.sample(list(img_dir.iterdir()),100)\n",
    "sample = list(img_dir.iterdir())\n",
    "\n",
    "transform = [transforms.Resize(224),transforms.RandomHorizontalFlip(),transforms.ToTensor()]\n",
    "test_ds = CDataset(sample,img_dir,transform=transform)\n",
    "\n",
    "batch_size=1\n",
    "sz=224\n",
    "test_dl = DataLoader(test_ds,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-35d3d8ef4a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabelFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stage_1_test_labels.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_ft' is not defined"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "num = 1000\n",
    "model_ft.eval()\n",
    "labelFile = 'stage_1_test_labels.csv'\n",
    "result = []\n",
    "from tqdm import tqdm\n",
    "with open(labelFile, 'w') as file:\n",
    "    file.write(\"patientId,Target\\n\")\n",
    "    \n",
    "    for data in tqdm(test_dl):\n",
    "        inputs,patientId = data\n",
    "        #model_ft.train(False)\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda(),requires_grad=True)\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        #optimizer.zero_grad()\n",
    "        #print(\"inputs:\",inputs)\n",
    "        #print(\"patientId:\",patientId)\n",
    "        #forward\n",
    "        outputs = model_ft(inputs)\n",
    "        #print(\"outputs\",outputs)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        if preds == 0:\n",
    "            #print(0)\n",
    "            result.append(0)\n",
    "            file.write(patientId[0]+\",0\\n\")\n",
    "        else:\n",
    "            #print(1)\n",
    "            result.append(1)\n",
    "            file.write(patientId[0]+\",1\\n\")\n",
    "        count+=1\n",
    "        if count>=num:\n",
    "            break\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 224, 224])\n",
      "outputs "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:19<02:59, 19.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7550, -0.8063],\n",
      "        [-0.9455,  0.6670],\n",
      "        [ 2.9659, -3.9412],\n",
      "        [ 0.5233, -0.5785],\n",
      "        [ 2.2332, -2.8215],\n",
      "        [ 1.0050, -1.1902],\n",
      "        [ 2.8417, -3.8217],\n",
      "        [ 1.0574, -1.1719],\n",
      "        [ 1.7487, -2.0800],\n",
      "        [ 0.6498, -0.6819],\n",
      "        [ 3.0455, -4.1296],\n",
      "        [ 2.9819, -4.0743],\n",
      "        [ 2.4180, -3.1848],\n",
      "        [ 1.0601, -1.1594],\n",
      "        [-0.1360, -0.0129],\n",
      "        [ 0.9436, -1.0720],\n",
      "        [ 2.8283, -3.8423],\n",
      "        [ 0.5188, -0.5591],\n",
      "        [ 0.8064, -0.7059],\n",
      "        [ 1.8847, -2.4305],\n",
      "        [ 3.3112, -4.5301],\n",
      "        [ 0.8992, -0.9676],\n",
      "        [ 1.6524, -2.0065],\n",
      "        [ 0.7263, -0.7705],\n",
      "        [-0.6534,  0.4520],\n",
      "        [ 2.3952, -3.1494],\n",
      "        [ 0.8283, -0.8128],\n",
      "        [ 2.7352, -3.6496],\n",
      "        [ 1.6761, -2.0558],\n",
      "        [ 0.7443, -0.7058],\n",
      "        [ 1.4513, -1.7138],\n",
      "        [ 2.7957, -3.8385],\n",
      "        [-0.1199,  0.0494],\n",
      "        [-1.0332,  0.7356],\n",
      "        [ 3.0191, -4.1386],\n",
      "        [-0.7424,  0.4654],\n",
      "        [ 2.0236, -2.4940],\n",
      "        [ 0.2735, -0.2819],\n",
      "        [ 2.7021, -3.6279],\n",
      "        [ 0.5339, -0.6224],\n",
      "        [ 3.0784, -4.2758],\n",
      "        [-0.8482,  0.5926],\n",
      "        [ 3.1262, -4.2273],\n",
      "        [ 2.6430, -3.5752],\n",
      "        [ 0.0231, -0.1186],\n",
      "        [ 0.5676, -0.5247],\n",
      "        [ 0.5206, -0.5149],\n",
      "        [ 0.7874, -0.8171],\n",
      "        [-0.0477, -0.0593],\n",
      "        [ 1.6029, -1.7426],\n",
      "        [ 0.2166, -0.2071],\n",
      "        [ 2.2026, -2.8311],\n",
      "        [ 2.5741, -3.4972],\n",
      "        [ 0.3409, -0.2905],\n",
      "        [ 0.4532, -0.5470],\n",
      "        [ 1.3717, -1.5335],\n",
      "        [ 0.1128, -0.1281],\n",
      "        [-0.0938,  0.0117],\n",
      "        [ 1.5107, -1.8056],\n",
      "        [-0.3350,  0.1421],\n",
      "        [-1.1785,  0.8863],\n",
      "        [ 0.0025, -0.0407],\n",
      "        [-0.9352,  0.6806],\n",
      "        [ 0.3956, -0.4633],\n",
      "        [ 0.6606, -0.6227],\n",
      "        [ 0.7280, -0.6656],\n",
      "        [ 1.3901, -1.5560],\n",
      "        [ 1.7421, -2.1305],\n",
      "        [ 0.4538, -0.3933],\n",
      "        [ 0.3667, -0.4855],\n",
      "        [-0.0463, -0.0197],\n",
      "        [-1.0982,  0.8111],\n",
      "        [ 1.5604, -1.9287],\n",
      "        [-0.3690,  0.2311],\n",
      "        [ 0.1766, -0.2358],\n",
      "        [ 0.7252, -0.8046],\n",
      "        [ 1.2725, -1.4671],\n",
      "        [ 0.6677, -0.6707],\n",
      "        [ 0.8465, -0.9458],\n",
      "        [ 0.3726, -0.5019],\n",
      "        [ 0.7948, -0.8154],\n",
      "        [ 2.8505, -3.8169],\n",
      "        [ 0.0498, -0.0765],\n",
      "        [ 1.0772, -1.2072],\n",
      "        [ 1.1243, -1.3059],\n",
      "        [ 0.6108, -0.5739],\n",
      "        [ 0.0666, -0.2035],\n",
      "        [ 0.9498, -1.0423],\n",
      "        [-0.3093,  0.1736],\n",
      "        [ 1.1207, -1.3302],\n",
      "        [ 0.5662, -0.5496],\n",
      "        [-0.2079,  0.0587],\n",
      "        [ 2.0953, -2.6645],\n",
      "        [ 1.6324, -2.0275],\n",
      "        [ 1.9079, -2.4972],\n",
      "        [ 2.6596, -3.5387],\n",
      "        [ 1.2455, -1.4262],\n",
      "        [-0.3430,  0.2222],\n",
      "        [ 0.9712, -1.0742],\n",
      "        [ 0.0322, -0.1202]], device='cuda:0', grad_fn=<ThAddmmBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f3e548694b42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f3e548694b42>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dicom_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f3e548694b42>\u001b[0m in \u001b[0;36mread_dicom_image\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_dicom_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_arr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mimg_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36mpixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mPixel\u001b[0m \u001b[0mData\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0mFE0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m00\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mNumPy\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \"\"\"\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_pixel_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;31m# Format strings spec'd according to python string formatting options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36m_get_pixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;31m# Use by pixel_array property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_pixel_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_pixel_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pixel_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36mconvert_pixel_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m                       if h and h.supports_transfer_syntax(self)]:\n\u001b[1;32m    809\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                     \u001b[0mpixel_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pixeldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pixel_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reshape_pixel_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_to_convert_to_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/pydicom/pixel_data_handlers/pillow_handler.py\u001b[0m in \u001b[0;36mget_pixeldata\u001b[0;34m(dicom_dataset)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mUncompressedPixelData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompressed_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/krf/anaconda/anaconda3/lib/python3.5/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##TEST ON TRAINING SET\n",
    "train_bb_df = pd.read_csv(PATH/'stage_1_train_labels.csv')\n",
    "#print(train_bb_df.head())\n",
    "\n",
    "train_bb_df['duplicate'] = train_bb_df.duplicated(['patientId'],keep=False)\n",
    "#print(train_bb_df[train_bb_df['duplicate']].head())\n",
    "\n",
    "detailed_df = pd.read_csv(PATH/'stage_1_detailed_class_info.csv')\n",
    "# merge two df\n",
    "class_df = train_bb_df.merge(detailed_df,on=\"patientId\")\n",
    "\n",
    "csv_df = class_df.filter(['patientId','Target'],)\n",
    "csv_df = csv_df.set_index('patientId',)\n",
    "#class_df.head(10)\n",
    "#print(csv_df.head(10))\n",
    "class TDataset(Dataset):\n",
    "    def __init__(self,ds,img_dir,class_df,transform=None,ext=None):\n",
    "        self.ds = ds\n",
    "        self.img_dir = img_dir\n",
    "        self.class_df = class_df\n",
    "        self.ext = ext or '.dcm'\n",
    "        self.transform = transforms.Compose(transform) if transform else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def read_dicom_image(self,loc):\n",
    "        img_arr = pydicom.read_file(loc.as_posix()).pixel_array\n",
    "        img_arr = img_arr/img_arr.max()\n",
    "        img_arr = (255*img_arr).clip(0,255).astype(np.uint8)\n",
    "        img_arr = Image.fromarray(img_arr).convert('RGB')\n",
    "        return img_arr\n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        img = self.read_dicom_image(self.ds[i])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        patientId = self.ds[i].name.split('.')[0]\n",
    "        kls = self.class_df[self.class_df['patientId'] == patientId]\n",
    "        return img,kls.iloc[0].Target\n",
    "\n",
    "img_dir = PATH/'stage_1_train_images'\n",
    "sample = random.sample(list(img_dir.iterdir()),1000)\n",
    "#sample = list(img_dir.iterdir())\n",
    "\n",
    "transform = [transforms.Resize(224),transforms.RandomHorizontalFlip(),transforms.ToTensor()]\n",
    "train_ds = TDataset(sample,img_dir,class_df,transform=transform)\n",
    "\n",
    "batch_size=100\n",
    "sz=224\n",
    "train_dl = DataLoader(train_ds,batch_size = batch_size)\n",
    "\n",
    "\n",
    "count = 0\n",
    "num = 100\n",
    "model_ft.eval()\n",
    "#labelFile = 'stage_1_train_labels_pred.csv'\n",
    "result = []\n",
    "from tqdm import tqdm\n",
    "running_corrects = 0\n",
    "for data in tqdm(train_dl):\n",
    "    inputs,labels = data\n",
    "    #print(data)\n",
    "    #print(labels)\n",
    "    #model_ft.train(False)\n",
    "    if use_gpu:\n",
    "        inputs = Variable(inputs.cuda(),requires_grad=True)\n",
    "        labels = Variable(labels.cuda())\n",
    "    else:\n",
    "        inputs,labels = Variable(inputs),Variable(labels)\n",
    "        \n",
    "        #print(\"inputs:\",inputs)\n",
    "        #print(\"patientId:\",patientId)\n",
    "        #forward\n",
    "    print(inputs.shape)\n",
    "    outputs = model_ft(inputs)\n",
    "    #print(\"outputs\",outputs)\n",
    "    _,preds = torch.max(outputs.data,1)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "print(running_corrects)\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(sum(sum(result)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
